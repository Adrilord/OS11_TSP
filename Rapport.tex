\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{color}
\usepackage{url}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[section]{placeins}
\usepackage{listings}
\lstset{
language=R,
basicstyle=\scriptsize\ttfamily,
commentstyle=\ttfamily\color{green},
numbers=left,
numberstyle=\ttfamily\color{black}\footnotesize,
stepnumber=1,
numbersep=5pt,
backgroundcolor=\color{white},
showspaces=false,
showstringspaces=false,
showtabs=false,
frame=single,
tabsize=2,
captionpos=b,
breaklines=true,
breakatwhitespace=false,
keywordstyle=\color{blue},
stringstyle=\color{magenta},
literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1
}
\usepackage[french,onelanguage,ruled,lined,linesnumbered]{algorithm2e}
\SetKw{Or}{ou}
\author{\textsc{TRAN Quoc Nhat Han} \& \textsc{Adrien WARTELLE}}
\title{Rapport de projet OS13\\Analyse de politique de maintenance}
\date{\today}
\begin{document}
\maketitle
\renewcommand{\contentsname}{Sommaire}
\tableofcontents
\begin{abstract}
A partir de données liées au fonctionnement d'un système, nous allons déterminer un modèle approprié, lié à l'état de celui-ci :
durée de vie ou niveau de défaillance. Nous allons ensuite, grâce au modèle, optimiser une politique de maintenance : basée sur l'âge ou conditionnelle. 
\end{abstract}
\section{Maintenance basée sur l'âge}
\subsection{Rappel}
Considérons un système non maintenu. En l'observant, nous obtenons une liste des dates de panne, grâce auxquelles nous pouvons construire une politique de remplacement systématique basée sur l'âge : \emph{Nous remettons à neuf le système lorsqu'il tombe en panne ou après une durée $t_0$ si il a survécu jusque là}.

Le but est de minimiser le coût moyen cumulé.
\begin{equation}
    \label{coutmoyduree}
    \mathbb{E}(C) = \frac{\mathbb{E}(C(S))}{\mathbb{E}(S)}
\end{equation}

Où $S$ est la variable aléatoire représentant la date de remplacement et $C(S)$ est le coût de maintenance cumulé à l'instant $S$ (sachant que $C(S)$ vaut $c_c (=1200)$ lors d'une maintenance corrective et $c_p(=800)$ lors d'une maintenance préventive).
\subsection{Modéliser la durée de vie du système}
L'importation de données de \texttt{FailureTimes\_5.csv} (l'annexe \ref{annexe:import_pannes}) montre des dates de pannes d'ordres grandement variées ($300$ à $27000$) (l'annexe \ref{annexe:premier_histo}). 

Mettre à l'exponentiel des valeurs extrêmes résultera en des valeurs nulles (si négatives) ou Inf (si positives) pour l'ordinateur, ce qui est indésirable. Alors nous devons forcément les réduire en les divisant par un scalaire \texttt{scale}, prenons par example $1000$.  (Figure \ref{histo1})
\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{img/premier_histo.png}
    \caption{Le premier histogramme de distribution de pannes}
    \label{histo1}
\end{figure}



Nous pouvons remarquer que les valeurs sont positives (étant données que ce sont des temps) et que la
distribution semble posséder deux parties importantes. En effet, les pannes se concentrent autour de 2 sommets, l'un à $[0; 0,5]$ et l'autre à $[4,5; 5]$. Ceci nous fait penser naturellement à un mixage de deux lois. Le premier sommet est suivi d'une pente forte, et la distribution locale de l'autre sommet a une forme de pic.
Nous avons donc pensé estimer un mixage de loi \emph{Exponentielle} et \emph{Gamma} afin de modéliser
les données. En effet la première partie correspondrait à une loi exponentielle tandis que la seconde à
une loi gamma.

La fonction de densité du mixage avec le paramètre $\theta  = \left( {p_1, p_2, \lambda ,\alpha ,\beta } \right)$ est donnée par :
\begin{align}
    \begin{split}
        \label{fMelExpGam}
        {f_\theta }\left( x \right) & = {p_1}{f_1}\left( x \right) + {p_2}{f_2}\left( x \right) \\
        & = {p_1}\lambda {e^{ - \lambda x}} + {p_2}\frac{{{\beta ^\alpha }}}{{\Gamma \left( \alpha  \right)}}{x^{\alpha  - 1}}{e^{ - \beta x}}
    \end{split}
\end{align}

Où $f_1, f_2$ désignent réspectivement $exp(\lambda)$ et $\Gamma(\alpha, \beta)$; $p_1, p_2 > 0: p_1 + p_2 = 1$.

Nous allons utiliser l'algorithme EM, la méthode la plus efficace pour estimer l'estimateur du maximum de vraisemblance (MLE) de mixage fini.

Soit $X$ la variable aléatoire de durée de vie du système. Soient $\left( {{x_1},...,{x_N}} \right)$ les observations.

Soit la matrice de probabilité d'appartenance $(\zeta_{ki})$ : $\zeta_{ki}$ vaut la probabilité que $x_i$ suive la loi $f_k$.
\begin{equation}
    \label{zeta}
    {\zeta _{ki}} = \frac{{{p_k}{f_k}\left( {{x_i}} \right)}}{{{p_1}{f_1}\left( {{x_i}} \right) + {p_2}{f_2}\left( {{x_i}} \right)}}\forall k = \overline {1,2}\ \forall i = \overline {1,N}
\end{equation}

La fonction de vraisemblance : 
\begin{equation}
    \label{funlik}
    \ln \Lambda  = \sum\limits_{i = 1}^N {\ln {f_\theta }\left( {{x_i}} \right)}  = \sum\limits_{i = 1}^N {\ln \left( {{p_1}{f_1}\left( {{x_i}} \right) + {p_2}{f_2}\left( {{x_i}} \right)} \right)}
\end{equation}

Nous cherchons à maximiser $\ln \Lambda$ en la dérivant selon $\lambda, \alpha, \beta$.

Pour $\lambda$ :
\begin{align}
    \frac{\partial }{{\partial \lambda }}\ln \Lambda  & = \sum\limits_{i = 1}^N {\frac{{{p_1}{e^{ - \lambda {x_i}}} - {p_1}\lambda {x_i}{e^{ - \lambda {x_i}}}}}{{{p_1}{f_1}\left( {{x_i}} \right) + {p_2}{f_2}\left( {{x_i}} \right)}}} \nonumber \\
    & = \sum\limits_{i = 1}^N {\frac{{{p_1}{f_1}\left( {{x_i}} \right)}}{{{p_1}{f_1}\left( {{x_i}} \right) + {p_2}{f_2}\left( {{x_i}} \right)}}\left( {\frac{1}{\lambda } - {x_i}} \right)} \nonumber  \\
    & = \frac{1}{\lambda }\sum\limits_{i = 1}^N {{\zeta _{1i}}}  - \sum\limits_{i = 1}^N {{\zeta _{1i}}{x_i}}  = 0 \nonumber \\
    \label{lambda}
    \Leftrightarrow \lambda  & = \frac{{\sum\limits_{i = 1}^N {{\zeta _{1i}}} }}{{\sum\limits_{i = 1}^N {{\zeta _{1i}}{x_i}} }}
\end{align}

Pour $\beta$ :
\begin{align}
    \frac{\partial }{{\partial \beta }}\ln \Lambda  & = \sum\limits_{i = 1}^N {\frac{{{p_2}x_i^{\alpha  - 1}}}{{\Gamma \left( \alpha  \right)}}\frac{{\alpha {\beta ^{\alpha  - 1}}{e^{ - \beta {x_i}}} - {\beta ^\alpha }{x_i}{e^{ - \beta {x_i}}}}}{{{p_1}{f_1}\left( {{x_i}} \right) + {p_2}{f_2}\left( {{x_i}} \right)}}} \nonumber \\
    & = \sum\limits_{i = 1}^N {\frac{{{p_2}{f_2}\left( {{x_i}} \right)}}{{{p_1}{f_1}\left( {{x_i}} \right) + {p_2}{f_2}\left( {{x_i}} \right)}}\left( {\frac{\alpha }{\beta } - {x_i}} \right)} \nonumber \nonumber \\
    & = \frac{\alpha }{\beta }\sum\limits_{i = 1}^N {{\zeta _{2i}}}  - \sum\limits_{i = 1}^N {{\zeta _{2i}}{x_i}}  = 0 \nonumber \\
    \label{beta}
    \Leftrightarrow \beta & = \alpha \frac{{\sum\limits_{i = 1}^N {{\zeta _{2i}}} }}{{\sum\limits_{i = 1}^N {{\zeta _{2i}}{x_i}} }}
\end{align}

Pour $\alpha$ : 
\begin{align*}
    \frac{\partial }{{\partial \alpha }}\ln \Lambda  & = \sum\limits_{i = 1}^N {\frac{{{p_2}{e^{ - \beta {x_i}}}}}{{{p_1}{f_1}\left( x \right) + {p_2}{f_2}\left( x \right)}}\left( {\frac{{\beta \left( {\ln \beta  + \ln {x_i}} \right){{\left( {\beta {x_i}} \right)}^{\alpha  - 1}}}}{{\Gamma \left( \alpha  \right)}} - {\beta ^\alpha }{x^{\alpha  - 1}}\frac{{\Psi \left( \alpha  \right)}}{{\Gamma \left( \alpha  \right)}}} \right)} \\
    & = \sum\limits_{i = 1}^N {\frac{{{p_2}{f_2}\left( {{x_i}} \right)}}{{{p_1}{f_1}\left( x \right) + {p_2}{f_2}\left( x \right)}}\left( {\ln \beta  + \ln {x_i} - \Psi \left( \alpha  \right)} \right)} \\
    & = \left( {\sum\limits_{i = 1}^N {{\zeta _{2i}}} } \right)\ln \beta  + \sum\limits_{i = 1}^N {{\zeta _{2i}}\ln {x_i}}  - \Psi \left( \alpha  \right)\left( {\sum\limits_{i = 1}^N {{\zeta _{2i}}} } \right) = 0 \\
    \Leftrightarrow 0 & = \ln \alpha  + \ln \frac{{\sum\limits_{i = 1}^N {{\zeta _{2i}}} }}{{\sum\limits_{i = 1}^N {{\zeta _{2i}}{x_i}} }} + \frac{{\sum\limits_{i = 1}^N {{\zeta _{2i}}\ln {x_i}} }}{{\sum\limits_{i = 1}^N {{\zeta _{2i}}} }} - \Psi \left( \alpha  \right) \text{ ( }\beta \text{ substitué par \eqref{beta})} \\
    \Leftrightarrow 0 & = \ln \alpha  - \Psi \left( \alpha  \right) - c
\end{align*}

Où $c = \ln \left( {\frac{{\sum\limits_{i = 1}^N {{\zeta _{2i}}{x_i}} }}{{\sum\limits_{i = 1}^N {{\zeta _{2i}}} }}} \right) - \frac{{\sum\limits_{i = 1}^N {{\zeta _{2i}}\ln \left( {{x_i}} \right)} }}{{\sum\limits_{i = 1}^N {{\zeta _{2i}}} }}$; $\Psi$ est la fonction digamma.

Selon la méthode de Newton-Rashphon, nous pouvons résoudre $\alpha$ numériquement avec ce formul itératif :
\[{\alpha _{r + 1}} = {\alpha _r} - \frac{{\ln {\alpha _r} + \Psi \left( {{\alpha _r}} \right) - c}}{{\frac{1}{{{\alpha _r}}} - \Psi '\left( {{\alpha _r}} \right)}}\]

\cite{bib:gamma} propose un autre formule convergeant plus vite :
\begin{equation}
    \label{alpha}
    \frac{1}{{{\alpha _{r + 1}}}} = \frac{1}{{{\alpha _r}}} + \frac{{\ln \left( {{\alpha _r}} \right) - \Psi \left( {{\alpha _r}} \right) - c}}{{\alpha_r^2\left( {\frac{1}{{{\alpha _r}}} - \Psi '\left( {{\alpha _r}} \right)} \right)}}
\end{equation}

Avec $\Psi'$ la fonction trigamma. L'itération part avec ${\alpha _0} = \frac{{0.5}}{c}$.

Au final, pour $p_k$:
\begin{equation}
    \label{p}
    {p_k} = \frac{{\sum\limits_{i = 1}^N {{\zeta _{ki}}} }}{N}\forall k = \overline {1,2}
\end{equation}

Etant donné \eqref{zeta}, \eqref{lambda}, \eqref{beta}, \eqref{alpha} et \eqref{p}, nous utilisons l'algorithme EM :
\begin{enumerate}
    \item \textbf{Initialisation :} Choisir $\theta_{0}$.
    \item \textbf{Etape E :} Evaluer $(\zeta_{ki})$ sachant $\theta_{c}$ en utilisant \eqref{zeta}.
    \item \textbf{Etape M :} Calculer $\theta_{c+1}$ à l'aide des équations \eqref{lambda}, \eqref{beta}, \eqref{alpha} et \eqref{p}. \\
    \emph{Note :} Pour $\alpha$, l'itération se termine quand $\left| {{\alpha _{r + 1}} - {\alpha _r}} \right| < {\varepsilon_\alpha }$ où $\varepsilon_\alpha$ est un réel positif fixé à l'initialisation.
    \item \textbf{Evaluation :} Si $\left\| {{\theta_{c + 1}} - {\theta_c}} \right\| < {\varepsilon _\theta }$ ($\varepsilon_\theta$ est un réel positif fixé à l'initialisation), l'algorithme s'arrête et $\theta = \theta_{c+1}$. \\ Sinon, reviens à l'étape E avec $c=c+1$.
\end{enumerate}

Avant de lancer l'algorithme, nous avons essayé d'obtenir un ensemble de paramètres initiaux $\theta_{0}$
qui soient cohérents avec la distribution des données. Nous avons choisi :
\[\left( {{p_{1_0}},{p_{2_0}},\lambda_{0} ,\alpha_{0} ,\beta_{0} } \right) = \left( {0.5;0.5;1;10;2} \right)\]

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/loi_initiale_Exp_Gamma.png}
    \caption{Mixage de la loi Exponentielle et Gamma : \textbf{paramètres initiaux}}
    \label{mixage_init}
\end{figure}

Après l'utilisation de l'algorithme EM, nous avons obtenu le résultat :
\[\left( {{p_1},{p_2},\lambda ,\alpha ,\beta } \right) = \left( {0.2194518;0.7805482;1.56738;1.665659;0.2332427} \right)\]

Nous avons tracé la fonction de densité $f_\theta$ trouvé (figure \ref{mixage}) et réalisé un test de Kolmogorov-Smirnov qui donne $p-value=0,9663111$ signifiant $96,63\%$ de nous tromper si nous rejetons ce modèle. Nous l'acceptons alors, quoiqu'il ne génère pas 2 sommets comme la remarque initiale. Le code est trouvable à l'annexe \ref{annexe:em_exp_gamma}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/EM_Exp_Gamma.png}
    \caption{Mixage de la loi Exponentielle et Gamma  :\textbf{paramètres finaux}}
    \label{mixage}
\end{figure}

\FloatBarrier

\subsection{La politique de maintenance basée sur l'âge}

Avec la fonction $f_\theta$ trouvée, nous allons pouvoir déterminer une politique optimale (selon le modèle) basée sur l'âge.

Nous avons par définition : $S = \min \left( {X,{t_0}} \right)$.

Autrement dit, $S = X{\mathbb{I}_{\left\{ {X < {t_0}} \right\}}} + {t_0}{\mathbb{I}_{\left\{ {X \geqslant {t_0}} \right\}}}$.

Cela se traduit avec le coût : $C\left( S \right) = {c_c}{\mathbb{I}_{\left\{ {X < {t_0}} \right\}}} + {c_p}{\mathbb{I}_{\left\{ {X \geqslant {t_0}} \right\}}}$, avec $c_c, c_p$ les coûts de maintenances correctives et préventives respectivement.

Le coût moyen :
\begin{align}
    \label{coutmoy}
    \mathbb{E}\left( {C\left( S \right)} \right) & = {c_c}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {X < {t_0}} \right\}}}} \right) + {c_p}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {X \geqslant {t_0}} \right\}}}} \right) \nonumber \\
    & = {c_c}P\left( {X < {t_0}} \right) + {c_p}P\left( {X \geqslant {t_0}} \right) \nonumber \\
    & = {c_c}{F_\theta }\left( {{t_0}} \right) + {c_p}\left( {1 - {F_\theta }\left( {{t_0}} \right)} \right) \nonumber \\
    & = \left( {{c_c} - {c_p}} \right){F_\theta }\left( {{t_0}} \right) + {c_p}
\end{align}

La durée moyenne :
\begin{align}
    \label{dureemoy}
    \mathbb{E}\left( S \right) & = \mathbb{E}\left( {X{\mathbb{I}_{\left\{ {X < {t_0}} \right\}}}} \right) + {t_0}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {X \geqslant {t_0}} \right\}}}} \right)\nonumber\\
    & = \int_0^{{t_0}} {x{f_\theta }\left( x \right)dx}  + {t_0}P\left( {X \geqslant {t_0}} \right) \nonumber \\
    & = x{F_\theta }\left( x \right)|_0^{{t_0}} - \int_0^{{t_0}} {{F_\theta }\left( x \right)dx}  + {t_0}\left( {1 - {F_\theta }\left( {{t_0}} \right)} \right) \nonumber \\
    & = {t_0} - \int_0^{{t_0}} {{F_\theta }\left( x \right)dx}
\end{align}

De \eqref{coutmoy} et \eqref{dureemoy}, nous détaillons le coût moyen sur une durée de temps \eqref{coutmoyduree} :
\begin{equation}
    \label{coutmoydureedet}
    \mathbb{E}\left( C \right) = \frac{{\mathbb{E}\left( {C\left( S \right)} \right)}}{{\mathbb{E}\left( S \right)}} = \frac{{\left( {{c_c} - {c_p}} \right){F_\theta }\left( {{t_0}} \right) + {c_p}}}{{{t_0} - \int_0^{{t_0}} {{F_\theta }\left( x \right)dx} }}
\end{equation}

L'annexe \eqref{annexe:optim_e_c} montre comment chercher l'optimum numériquement. La valeur minimum est $t_0 = 27,29639$ (mille heures), correspondant à un coût moyen par durée de temps de $210,6402$ (euros / mille heures). Nous constatons que $t_0^{min}$ est très proche du maximum de durée de vie, indiquant que l'optimisation de $t_0$ est inutile car le système ne viellit que très peu.\footnote{La loi de durée de vie trouvée est très proche d'une loi exponentielle car c'est celle-ci qui pré-pondère et cette loi implique un système toujours neuf (d'age 0), et donc sans besoin de maintenance basée sur l'âge. On peut facilement montrer que l'optimum de $t_{0}^{*}$ dans le cas exponentiel est infini.}.

\clearpage

\section{Maintenance basée sur dégradation}
\subsection{Rappel}
En observant de multiples systèmes identiques, nous effectuons des mesures de dégradation sur des intervalles de temps réguliers tout au long de leurs durée de vie.

La valeur limite de dégradation est $L=20$. C'est-à-dire que lorsque le niveau de dégradation dépasse $L$, le système tombe en panne et nous ne pourrons plus le mesurer.

On souhaite mettre en place une politique de maintenance conditionnelle, basée sur un seuil $M$ inférieur à $L$ et l'intervalle de temps $\Delta T$ entre les inspections répétée. Appelons $X_t$ le niveau de dégradation à l'instant $t$ (instant d'une inspection) :
\begin{itemize}
    \item Si $X_t < M$, nous laissons le système tel quel.
    \item Si $M \leq X_t < L$, un remplacement préventif est réalisé au coût $c_p$. Et puis $X_t$ est remis à $0$.
    \item Si $X_t \geq L$, un remplacement correctif est réalisé au coût $c_c$. Et puis $X_t$ est remis à $0$.
\end{itemize}

Le but est minimiser le coût moyen sur une durée de temps \eqref{coutmoyduree} en choisissant bien le seuil $M$ et l'intervalle d'inspection $\Delta T$.
\subsection{Modéliser la dégradation du système}

Avec les données de \texttt{DegradLevel\_2.csv}, nous traçons leurs processus de dégradation (figure \eqref{fig:trace_degrad}). (Les annexes \eqref{annexe:import_degrad} et \eqref{annexe:premier_plot_degrad})

Comme les temps d'inspection sont de l'ordre du millier, il faudrait les diviser par un scalaire (par example, $scale = 1000$) afin d'assurer la précision des calculs numériques.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{img/trace_degrad.png}
    \caption{Traçe de dégradation du système}
    \label{fig:trace_degrad}
\end{figure}

Nous voyons que les accroissements sont positifs, suggérant un modèle de processus Gamma.

Soit $X(t)$ la variable aléatoire de dégradation du système. Supposons que $X(t) - X(s) \sim \Gamma(a(t-s),b)\,\forall t > s > 0$. Nous allons estimer les paramètres $a,b$ en modélisant la distribution des incréments entre deux moments successifs.

Fixons $t-s = \delta = 0.8$, car les mesures données sont effectués au bout de chaque intervalle de $0.8$.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{img/histo_degrad.png}
    \caption{Histogramme des incréments de l'intervalle $\delta = 0.8$}
    \label{fig:histo_degrad}
\end{figure}

A l'aide du librairie MASS : $\left( {a;b} \right) = \left( {\frac{\alpha }{\delta };\beta } \right) = \left( {2.843101;1.140354} \right)$ où $(\alpha, \beta)$ sont les paramètres estimés par MASS. Le code est mis à l'annexe \eqref{annexe:estim_degrad}.

Un test rapide de Kolmogorov-Smirnov nous donne $p-value = 0.8651934$, indiquant le modèle est largement acceptable.
\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{img/histo_dens_degrad.png}
    \caption{Histogramme et la courbe de densité estimé des incréments de l'intervalle $\delta = 0.8$}
    \label{fig:histo_dens_degrad}
\end{figure}

D'autant plus, si nous refaisons les calculs ci-dessus avec $\delta = 1.6, 2.4, 3.2, etc.$, nous voyons les valeurs de $a$ et $b$ ne varient pas trop. Alors, nous choisissons le couple $(a,b)$ avec $p$ le plus grand. ($\delta$ trop grand réduira nombreux de données, résultant une perte importante de précision)

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{img/histo_dens_degrad_1_6.png}
    \caption{Histogramme et la courbe de densité estimé des incréments de l'intervalle $\delta = 1.6$}
    \label{fig:histo_dens_degrad_1_6}
\end{figure}

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        $\delta$ & $a$ & $b$ & $p$ \\
        \hline
        0.8 & 2.8431009 & 1.1403540 & 0.8651934\\
        1.6 & 3.0207719 & 1.2091646 & 0.9919939\\
        2.4 & 3.0187497 & 1.1907719 & 0.1279252\\
        3.2 & 2.997763 & 1.185547 & 0.300610\\
        4.0 & 3.5036580 & 1.4061063 & 0.6307951\\
        \hline
    \end{tabular}
    \caption{Calcul $(a,b)$ avec différents $\delta$}
\end{table}

Au final, nous choisissons $X(t) - X(s) \sim \Gamma(a(t-s),b)\  \forall t > s > 0$, $\delta=1.6$ et $(a,b) = (3.0207719;1.2091646)$.

\subsection{La politique de maintenance basée sur dégradation}

Cette politique, outre que $c_c=1200$ et $c_p=800$, introduit ainsi le coût d'inspection répétive $c_i = 10$.

Soit $S$ la variable aléatoire représentant la date de remplacement; $C(S)$ est le coût de maintenance cumulé à l’instant $S$, et $N(S)$ le nombre d'inspections depuis la dernière remplacement jusqu'à $S$.

\begin{equation}
    \label{c_s_de}
    C\left( S \right) = {c_i}N\left( S \right) + {c_p}{\mathbb{I}_{\left\{ {L > {X_{N\left( S \right)}} \geq M} \right\}}} + {c_c}{\mathbb{I}_{\left\{ {{X_{N\left( S \right)}} \geq L} \right\}}}
\end{equation}

Posons ${F_t} = \Gamma \left( {at,b} \right)$ et les instants d'inspections ${t_1},{t_2},...,{t_{N\left( S \right)}}$ avec ${t_{j + 1}} - {t_j} = \Delta T$. Puisque $t_0 = 0$, nous aurons ${t_k} = k\Delta T$ et $X_{t_k} \sim F_{k\Delta T}$.

Comme le calcul analytique de $C(S)$ et $N(S)$ devient grossier (l'annexe \eqref{annexe:ana_e_c}), nous passons à la méthode Monté Carlo, qui nous permet d'estimer la vraie valeur en répétant un nombre suffisant de simulations.
\begin{itemize}
    \item L'algorithme \eqref{algo:s} calcule la durée de vie d'une simulation.
    \item L'algorithme \eqref{algo:c_s} calcule le coût d'une simulation.
    \item L'algorithme \eqref{algo:e_c} simule de multiples processus et retourne une valeur approximative de $\mathbb{E}(C)$.
    \item L'algorithme \eqref{algo:optim_degrad} trouve l'optimum sur une zone de recherche.
\end{itemize}

\begin{algorithm}[!h]
    \caption{Mesurer la durée de vie d'un processus}
    \label{algo:s}
    \KwIn{$p$ le processus\newline
        $\Delta T$ l'intervalle d'inspection\newline
        $M$ le seuil de maintenance préventive
    }
    \KwOut{$S$ la durée de vie}
    $len \leftarrow $ longeur de $p$\;
    \eIf{$p_{len} < M$}{
        \tcp{La simulation n'est pas suffisante longue}
        \Return{0}
    }{
        $n_s \leftarrow$ le dernier index de $p$ tel que $p_{n_s} < M$\;
        \Return{$n_s + 1$}
    }
\end{algorithm}

\begin{algorithm}[!h]
    \caption{Mesurer le coût de maintenance d'un processus}
    \label{algo:c_s}
    \KwIn{$p$ le processus\newline
    $M$ le seuil
    }
    \KwOut{$C(S)$ le coût de maintenance}
    $cout \leftarrow 0$\;
    $len \leftarrow $ longeur de $p$\;
    \If{$p_{len} \geq M$}{
        $n_s \leftarrow$ le dernier index de $p$ tel que $p_{n_s} < M$\;
        \tcp{$n_s$ correspond le nombre d'inspection}
        $cout \leftarrow cout + c_i * n_s$\;
        \tcp{A l'inspection suivante}
        \eIf{$p_{n_s + 1} \geq L$}{
            \tcp{Le système est tombé en panne}
            $cout \leftarrow cout + c_c$\;
        }{
            \tcp{Le système fonctionne encore}
            $cout \leftarrow cout + c_p$\;
        }
    }
    \tcp{Le coût est zéro si le niveau de dégradation ne dépasse pas encore $M$}
    \Return{$cout$}
\end{algorithm}

\begin{algorithm}[!h]
    \caption{Simuler le processus et calculer $\widehat{\mathbb{E}(C)}$}
    \label{algo:e_c}
    \KwIn{$\Delta T$ l'intervalle d'inspection\newline
    $M$ le seuil\newline
    $nSim$ le nombre de simulation\newline
    $nStep$ le nombre d'inspection maximale}
    \KwOut{$\widehat{\mathbb{E}(C)}$ la valeur approximative}
    Générer la matrice de l'incréments $simStep$ de taille $nSim \times nStep$ aux valeurs aléatoires selon la loi $\Gamma(a\Delta T, b)$\;
    Calculer la matrice de processus $simProc$ de taille $nSim \times nStep$ en faisant la somme cumulative de $simStep$ horizontallement\;
    $simTime \leftarrow$ les durées de vie de processus en appliquant l'algorithme \eqref{algo:s}\;
    $simCost \leftarrow$ les coûts de processus en appliquant l'algorithme \eqref{algo:c_s}\;
    $meanSimCost \leftarrow$ la moyenne de tous les coûts non nuls de $simCost$\;
    $meanSimTime \leftarrow$ la moyenne de durée de vie non nuls de $simTime$\;
    $meanCostTime \leftarrow \frac{meanSimCost}{meanSimTime}$\;
    \If{$meanSimCost$ est \texttt{NaN} \Or $meanSimTime$ est \texttt{NaN}}{
        $meanCostTime \leftarrow MAX\_DOUBLE$\;
    }
    \Return{$meanCostTime$}
\end{algorithm}

\begin{algorithm}[!h]
    \caption{Optimiser la politique de maintenance basée sur dégradation}
    \label{algo:optim_degrad}
    \KwIn{$[L_{\Delta T}, U_{\Delta T}]$ l'intervalle de recherche de $\Delta T$\newline
        $[L_{M}, U_{M}]$ l'intervalle de recherche de $M$\newline
        $\tau$ la tolérance\newline
        $d_{\Delta T}$ le nombre de points à évaluer pour $\Delta T$\newline
        $d_M$ le nombre de points à évaluer pour $M$\newline
        $e_{\Delta T}$ le ratio de réduction sur l'intervalle de $\Delta T$\newline
        $e_M$ le ratio de réduction sur l'intervalle de $M$
    }
    \KwOut{$\Delta T^*$ l'intervalle d'inspection optimal\newline
        $M^*$ le seuil optimal\newline
        $o^*$ la valeur objective optimale
    }
    \tcp{Suivre le principe de diachotomie}
    $\Delta T^* \leftarrow 0$\;
    $M^* \leftarrow 0$\;
    $o^* \leftarrow 0$\;
    \While{${\left( {\frac{{{L_{\Delta T}} - {U_{\Delta T}}}}{{{d_{\Delta T}}}}} \right)^2} + {\left( {\frac{{{L_M} - {U_M}}}{{{d_M}}}} \right)^2} \geqslant \tau^2 $}{
        \tcp{Evaluer}
        $I_{\Delta T} \leftarrow$ l'ensemble de $d_{\Delta T}$ points égaux-distances de $[L_{\Delta T}, U_{\Delta T}]$\;
        $I_{M} \leftarrow$ l'ensemble de $d_{M}$ points égaux-distances de $[L_{M}, U_{M}]$\;
        $Z \leftarrow $ résultats de l'application de  l'algorithme \eqref{algo:e_c} pour chaque point sur la grille $I_{\Delta T} \times I_M$\;
        \tcp{Chercher le minimum}
        $(i^*,j^*) \leftarrow $ l'indice du minimum de $Z$\;
        $\Delta T^* \leftarrow $ l'élément $i^*$-ième de $I_{\Delta T}$\;
        $M^* \leftarrow $ l'élément $j^*$-ième de $I_{M}$\;
        $o^* \leftarrow Z_{i^*,j^*}$\;
        \tcp{Ajuster la nouvelle zone de recherche autour du minimum actuel}
        ${l_{\Delta T}} \leftarrow {L_{\Delta T}} - {U_{\Delta T}}$\;
        ${l_M} \leftarrow {L_M} - {U_M}$\;
        \tcp{La nouvelle zone ne doit pas déborder celle précédente}
        ${L_{\Delta T}} \leftarrow \min \left( {\Delta {T^*} + \frac{{{l_{\Delta T}}}}{{{e_{\Delta T}}}},{L_{\Delta T}}} \right)$\;
        ${U_{\Delta T}} \leftarrow \max \left( {\Delta {T^*} - \frac{{{l_{\Delta T}}}}{{{e_{\Delta T}}}},{U_{\Delta T}}} \right)$\;
        ${L_M} \leftarrow \min \left( {{M^*} + \frac{{{l_M}}}{{{e_M}}},{L_M}} \right)$\;
        ${U_M} \leftarrow \max \left( {{M^*} - \frac{{{l_M}}}{{{e_M}}},{U_M}} \right)$\;
    }
    \Return{$(\Delta T^*, M^*, o^*)$}
\end{algorithm}

\FloatBarrier
Puisque l'algorithme \eqref{algo:e_c} utilise du calcul matriciel pour accélérer le traitement, $nStep$ doit être fixé judicieusement pour ne pas avoir "trop" de simulations où $X_{t_{nStep}} < M$ (ce qui va forcer les valeurs de $C(S)$ et $S$ à zéro selon les algorithmes \eqref{algo:s} et \eqref{algo:c_s}). Soit $\alpha$ la probabilité de cet événement.
\begin{align*}
    P\left( {{X_{{t_{nStep}}}} < M} \right) & = \alpha  \\
    \Leftrightarrow {F_{nStep*\Delta T}}\left( M \right) & = \alpha \\
    \Leftrightarrow \Gamma \left( {a*nStep*\Delta T,b} \right)\left( M \right) & = \alpha 
\end{align*}

Nous testons quelques valeurs de $F$. Comme $F$ est croissant, nous l'évaluons directement à $M=20$.

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|}
      \hline
      $nStep * \Delta T$ &  $\Gamma \left( {a*nStep*\Delta T,b} \right)\left( 20 \right)$\\
      \hline
      8 & 0.5284405 \\
      10 & 0.1319799 \\
      12 & 0.01300913 \\
      13 & 0.002925565 \\
      14 & 0.000533971 \\
      \hline
    \end{tabular}
    \caption{Estimation de $nStep * \Delta T$}
    \label{tab:nstep}
\end{table}

La fonction distribution décroît selon $nStep*\Delta T$. Et pourtant, $\alpha \leq 1\%$ nous suffit. D'autant plus, la traitement ralentit remarquablement lorsque $nStep$ est grand. C'est pourquoi, basé sur la table \eqref{tab:nstep}, nous emploirons
\[nStep = \left\lfloor {\frac{{13}}{{\Delta T}}} \right\rfloor \]

Le code implémenté se situe à l'annexe \ref{annexe:optim_degrad}. 

Bien que le résultat n'est pas stable à cause de l'approche Monté Carlo, nous pouvons arriver à une valeur approximative après plusieurs itérations de l'algorithme \eqref{algo:optim_degrad} sur l'intervalle $[0.001, 4] \times [0, 20]$ : 
\begin{align*}
    (\Delta T^*, M^*, o^*) = (& 0.001007627 \text{ (mille heures)},\\
    & 18.58027,\\
    & 10.10541 \text{ (euros/mille heures)})
\end{align*}

Ce résultat nous semble logique car :
\begin{itemize}
    \item $\Delta T^*$ faible (grâce à  coût $c_i$ qui est faible) nous permet d'observer mieux et juste à temps le système.
    \item $M^*$ proche de $L$ va "remplacer" la plupart des coûts $c_c$ par $c_p$ pour économiser.
\end{itemize}

\begin{figure}
    \centering
    \caption{Représentation graphique de $E(C)$}
    \label{fig:e_c}
    \includegraphics[width=0.8\textwidth]{img/E_C_degrad.png}
\end{figure}

\clearpage
\section{Annexe}
\subsection{L'importation de données de pannes}
\label{annexe:import_pannes}
\lstinputlisting[language=R]{part1/import_failures.R}
\subsection{Le premier histogramme de distribution de pannes}
\label{annexe:premier_histo}
\lstinputlisting[language=R]{part1/premier_histo.R}
\subsection{Estimer le mixage de la loi Exponentielle et Gamma}
\label{annexe:em_exp_gamma}
\lstinputlisting[language=R]{part1/EM_Exp_Gamma.R}
\subsection{Optimiser le coût moyen sur une durée de temps}
\label{annexe:optim_e_c}
\lstinputlisting[language=R]{part1/optimize_t0_failures.R}
\subsection{Importer les valeurs de dégradation}
\label{annexe:import_degrad}
\lstinputlisting[language=R]{part2/import_degrad.R}
\subsection{Premiers traçes de dégradation}
\label{annexe:premier_plot_degrad}
\lstinputlisting[language=R]{part2/plot_degrad.R}
\subsection{Estimation de paramètres de dégradations}
\label{annexe:estim_degrad}
\lstinputlisting[language=R]{part2/estime_degrad.R}
\subsection{Calcul analytique de maintenance conditionnelle}
\label{annexe:ana_e_c}
Rappelons que ${X_{{t_k}}} \sim {F_{k\Delta t}}$ et \eqref{c_s_de}:
\[C\left( S \right) = {c_i}N\left( S \right) + {c_p}{\mathbb{I}_{\left\{ {L > {X_{N\left( S \right)}} \geqslant M} \right\}}} + {c_c}{\mathbb{I}_{\left\{ {{X_{N\left( S \right)}} \geqslant L} \right\}}}\]

D'où
\begin{align*}
    \label{e_c_s_de}
    \mathbb{E}\left( {C\left( S \right)} \right) & = {c_i}\mathbb{E}\left( {N\left( S \right)} \right) + {c_p}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {L > {X_{{t_{N\left( S \right)}}}} \geqslant M} \right\}}}} \right) \\
    & + {c_c}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {{X_{{t_{N\left( S \right)}}}} \geqslant L} \right\}}}} \right)
\end{align*}

Détaillons le nombre moyen d'inspection $\mathbb{E}\left( {N\left( S \right)} \right)$ :
\[\mathbb{E}\left( {N\left( S \right)} \right) = \sum\limits_{k = 1}^\infty  {kP\left( {N\left( S \right) = k} \right)}  = P\left( {N\left( S \right) = 1} \right) + \sum\limits_{k = 2}^\infty  {kP\left( {N\left( S \right) = k} \right)} \]

Or
\begin{align*}
    P\left( {N\left( S \right) = 1} \right) & = P\left( {{X_{{t_1}}} \geqslant M} \right) \\
    & = 1 - {F_{\Delta T}}\left( M \right) \\
    P\left( {N\left( S \right) = k} \right) & = P\left( {{X_{{t_k}}} \geqslant M \wedge {X_{{t_{k - 1}}}} < M} \right) \\
    & = P\left( {\Delta X \geqslant M - {X_{{t_{k - 1}}}} \wedge {X_{{t_{k - 1}}}} < M} \right) \\
    & = \int_0^M {P\left( {\Delta X \geqslant M - \xi } \right)P\left( {{X_{{t_{k - 1}}}} = \xi } \right)d\xi }\\
    & = \int_0^M {\left( {1 - {F_{\Delta T}}\left( {M - \xi } \right)} \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } \\
    & = \int_0^M {{f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi }  - \int_0^M {{F_{\Delta T}}\left( {M - \xi } \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } \\
    & = {F_{\left( {k - 1} \right)\Delta T}}\left( M \right) - \int_0^M {{F_{\Delta T}}\left( {M - \xi } \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi }
\end{align*}

Par conséquence, 
\begin{align}
    \label{e_n_s_de}
    & \mathbb{E}\left( {N\left( S \right)} \right) = 1 - {F_{\Delta T}}\left( M \right) \nonumber \\
    & + \sum\limits_{k = 2}^\infty  {k\left( {{F_{\left( {k - 1} \right)\Delta T}}\left( M \right) - \int_0^M {{F_{\Delta T}}\left( {M - \xi } \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } } \right)}
\end{align}

En suite, nous exprimons la probabilité de maintenance préventive :
\begin{align*}
    & \mathbb{E}\left( {{\mathbb{I}_{\left\{ {L > {X_{{t_{N\left( S \right)}}}} \geqslant M} \right\}}}} \right) = \sum\limits_{k = 1}^\infty  {P\left( {L > {X_{{t_k}}} \geqslant M|{X_{{t_{k - 1}}}} < M} \right)} \\
    & k = 1 :\, P\left( {L > {X_{{t_1}}} \geqslant M} \right) = {F_{\Delta T}}\left( L \right) - {F_{\Delta T}}\left( M \right) \\
    & \forall k \geqslant 2 : \\
    & P\left( {L > {X_{{t_k}}} \geqslant M|{X_{{t_{k - 1}}}} < M} \right) \\
    & = \frac{{P\left( {L > {X_{{t_k}}} \geqslant M \wedge {X_{{t_{k - 1}}}} < M} \right)}}{{P\left( {{X_{{t_{k - 1}}}} < M} \right)}} \\
    & = \frac{{P\left( {{X_{{t_{k - 1}}}} < M \wedge \Delta X \geqslant M - {X_{{t_{k - 1}}}} \wedge \Delta X < L - {X_{{t_{k - 1}}}}} \right)}}{{P\left( {{X_{{t_{k - 1}}}} < M} \right)}} \\
    & = \frac{{\int_0^M {P\left( {\Delta X \geqslant M - \xi  \wedge \Delta X < L - \xi } \right)P\left( {{X_{{t_{k - 1}}}} = \xi } \right)d\xi } }}{{{F_{\left( {k - 1} \right)\Delta T}}\left( M \right)}} \\
    & = \frac{{\int_0^M {\left( {{F_{\Delta T}}\left( {L - \xi } \right) - {F_{\Delta T}}\left( {M - \xi } \right)} \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } }}{{{F_{\left( {k - 1} \right)\Delta T}}\left( M \right)}}
\end{align*}

Ceci induit que :
\begin{align}
    \label{p_p_de}
    & \mathbb{E}\left( {{\mathbb{I}_{\left\{ {L > {X_{{t_{N\left( S \right)}}}} \geqslant M} \right\}}}} \right) = {F_{\Delta T}}\left( L \right) - {F_{\Delta T}}\left( M \right) \nonumber \\
    & + \sum\limits_{k = 2}^\infty  {\frac{{\int_0^M {\left( {{F_{\Delta T}}\left( {L - \xi } \right) - {F_{\Delta T}}\left( {M - \xi } \right)} \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } }}{{{F_{\left( {k - 1} \right)\Delta T}}\left( M \right)}}}
\end{align}

Puis, de même manière, la probabilité de maintenance corrective sera :
\begin{align*}
    & \mathbb{E}\left( {{\mathbb{I}_{\left\{ {{X_{{t_{N\left( S \right)}}}} \geqslant L} \right\}}}} \right) = \sum\limits_{k = 1}^\infty  {P\left( {{X_{{t_k}}} \geqslant L|{X_{{t_{k - 1}}}} < M} \right)} \\
    & k = 1 : \, P\left( {{X_{{t_1}}} \geqslant L} \right) = {F_{\Delta T}}\left( L \right) \\
    & \forall k \geqslant 2: \\
    & P\left( {{X_{{t_k}}} \geqslant L|{X_{{t_{k - 1}}}} < M} \right) \\
    & = \frac{{P\left( {{X_{{t_k}}} \geqslant L \wedge {X_{{t_{k - 1}}}} < M} \right)}}{{P\left( {{X_{{t_{k - 1}}}} < M} \right)}} \\
    & = \frac{{P\left( {\Delta X \geqslant L - {X_{{t_{k - 1}}}} \wedge {X_{{t_{k - 1}}}} < M} \right)}}{{P\left( {{X_{{t_{k - 1}}}} < M} \right)}} \\
    & = \frac{{\int_0^M {P\left( {\Delta X \geqslant L - \xi } \right)P\left( {{X_{{t_{k - 1}}}} = \xi } \right)d\xi } }}{{P\left( {{X_{{t_{k - 1}}}} < M} \right)}}\\
    & = \frac{{\int_0^M {\left( {1 - {F_{\Delta T}}\left( {L - \xi } \right)} \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } }}{{{F_{\left( {k - 1} \right)\Delta T}}\left( M \right)}}
\end{align*}

D'où :
\begin{align}
    \label{p_c_de}
    & \mathbb{E}\left( {{\mathbb{I}_{\left\{ {{X_{{t_{N\left( S \right)}}}} \geqslant L} \right\}}}} \right) = {F_{\Delta T}}\left( L \right) \nonumber \\
    & + \sum\limits_{k = 2}^\infty  {\frac{{\int_0^M {\left( {1 - {F_{\Delta T}}\left( {L - \xi } \right)} \right){f_{\left( {k - 1} \right)\Delta T}}\left( \xi  \right)d\xi } }}{{{F_{\left( {k - 1} \right)\Delta T}}\left( M \right)}}}
\end{align}

Attention, parce que nous considérons $S$ l'instant de la dernière inspection :
\[S = {t_{N\left( S \right)}} = N\left( S \right)\Delta T \Rightarrow \mathbb{E}\left( S \right) = \mathbb{E}\left( {N\left( S \right)} \right)\Delta T\]

Alors :
\begin{align*}
    \mathbb{E}\left( C \right) & = \frac{{\mathbb{E}\left( {C\left( S \right)} \right)}}{{\mathbb{E}\left( S \right)}} \\
    & = \frac{{{c_i}\mathbb{E}\left( {N\left( S \right)} \right) + {c_p}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {L > {X_{{t_{N\left( S \right)}}}} \geqslant M} \right\}}}} \right) + {c_c}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {{X_{{t_{N\left( S \right)}}}} \geqslant L} \right\}}}} \right)}}{{\mathbb{E}\left( {N\left( S \right)} \right)\Delta T}} \\
    & = \frac{{{c_i}}}{{\Delta T}} + \frac{1}{{\Delta T}}\frac{{{c_p}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {L > {X_{{t_{N\left( S \right)}}}} \geqslant M} \right\}}}} \right) + {c_c}\mathbb{E}\left( {{\mathbb{I}_{\left\{ {{X_{{t_{N\left( S \right)}}}} \geqslant L} \right\}}}} \right)}}{{\mathbb{E}\left( {N\left( S \right)} \right)}}
\end{align*}

Substiter par \eqref{e_n_s_de}, \eqref{p_p_de} et \eqref{p_c_de} nous donnera le formule exacte de coût moyen par une durée de temps.
\subsection{Optimisation de maintenance basée sur dégradations}
\label{annexe:optim_degrad}
\lstinputlisting[language=R]{part2/optimize_degrad_montecarlo.R}

\begin{thebibliography}{9}
    \bibitem{bib:gamma} Minka, Thomas P. (2002). "Estimating a Gamma distribution"

    \url{https://tminka.github.io/papers/minka-gamma.pdf}
\end{thebibliography}
\end{document}